{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "33deea089a10ae4ee9588de2c52027207086d61a"
   },
   "source": [
    "# **AVALIAÇÃO DE ALGORITMOS**\n",
    "\n",
    "> Todo o processo aqui tratado será feito com algoritmos de classificação, porém tudo se aplica da mesma maneira para os algoritmos de regressão, porém no lugar de utilizar os valores de precisão para colocar na tabela, utilize o score do algoritmo com relação a base de testes, porém também pode-se utilizar o erro quadrático médio como parâmetro.\n",
    "\n",
    "> Não irei rodar nenhum dos códigos, pois antes seria necessário efetuar os treinamentos de todos os métodos, e isso não é muito viável nesse caso. Então apenas deixarei a implantação.\n",
    "\n",
    "> Tenha em mente que previsores = x, classe = y.\n",
    "\n",
    "Para verificar qual é o melhor algoritmo para cada base de dados que se está trabalhando, não basta aplicar todos os métodos e ver qual é o que resultou na maior precisão.\n",
    "\n",
    "---\n",
    "- Link para aprender mais:\n",
    "    - [Machine Learning Underfitting e Overfitting - IAexpert](https://iaexpert.com.br/index.php/2018/06/22/machine-learning-underfitting-e-overfitting/).\n",
    "---\n",
    "## VALIDAÇÃO CRUZADA\n",
    "\n",
    "Ao dividir uma base de dados em treinamento e teste pode-se ocorrer de que dados que foram utilizados para teste sejam bons para a criação do algoritmo, visto que eles pode conter uma boa caracterização do objeto de estudo. Para evitar que isso aconteça:\n",
    "- Divide-se a base em `k` partes\n",
    "- Uma dessas partes será utilizada para teste e o restante para treinamento.\n",
    "- Agora a parte que foi utilizada para teste anteriormente passa a ser utilizada para treinamento, e uma das outras passa para teste.\n",
    "- O processo é repetido `k` vezes, assim todas as partes serão utilizadas para teste e treinamento.\n",
    "- A precisão do algoritmo será dada pela média das precisões em cada situação. \n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/1/1c/K-fold_cross_validation_EN.jpg)\n",
    "\n",
    "Fonte: https://en.wikipedia.org/wiki/Cross-validation_(statistics)\n",
    "\n",
    "---\n",
    "- Links para aprender mais:\n",
    "    - [Machine Learning Introdução a Validação Cruzada - IAexpert](https://iaexpert.com.br/index.php/2018/06/13/machine-learning-introducao-a-validacao-cruzada/).\n",
    "    - [Model Evaluation in Regression Models - Cognitive Class](https://youtu.be/81vMze7TzuU)\n",
    "---    \n",
    "### **K-Fold cross validation**\n",
    "\n",
    "Para efetuar a validação cruzada siga o código abaixo:\n",
    "\n",
    "```python\n",
    "#------------------------Pegando os valores pre processados-------------------#\n",
    "# Não divida em base de treinamento e teste.                                  #\n",
    "# Pegar apenas previsores e classe como um todo                               #\n",
    "#-----------------------------------------------------------------------------#\n",
    "\n",
    "#---------------------------------Bibliotecas---------------------------------#\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# import classe necessária para o método desejado.\n",
    "\n",
    "#------------------Criar classificador com o método desejado------------------#\n",
    "# Não utiliza o método fit.                                                   #\n",
    "#-----------------------------------------------------------------------------#\n",
    "                                      #\n",
    "                                      #\n",
    "                                      #\n",
    "#--------------------Precisão em cada um dos cv testes------------------------#\n",
    "# cv = número de divisões, consequentemente 10 testes                         #\n",
    "#-----------------------------------------------------------------------------#\n",
    "resultados = cross_val_score(classificador, previsores, classe, cv = 10)\n",
    "\n",
    "#------------------------Retorna a média dos resultados-----------------------#\n",
    "resultados.mean()\n",
    "\n",
    "#--------------------Retorna o desvio padrão dos resultados-------------------#\n",
    "# Valores altos de desvio padrão indicam overfitting                          #\n",
    "#-----------------------------------------------------------------------------#\n",
    "resultados.std()\n",
    "\n",
    "```\n",
    "\n",
    "Para exemplificar vou utilizar o método de Naive Bayes por ser mais rápido.\n",
    "\n",
    "- **Classe**:\n",
    "    - [sklearn.model_selection.cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score)\n",
    "\n",
    "```python\n",
    "#---------------------------------Bibliotecas---------------------------------#\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#------------------Criar classificador com o método desejado------------------#\n",
    "# Não utiliza o método fit.                                                   #\n",
    "#-----------------------------------------------------------------------------#\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classificador = GaussianNB()\n",
    "\n",
    "#--------------------Precisão em cada um dos cv testes------------------------#\n",
    "# cv = número de divisões, consequentemente 10 testes                         #\n",
    "#-----------------------------------------------------------------------------#\n",
    "resultados = cross_val_score(classificador, previsores, classe, cv = 10)\n",
    "print('resultados: {}\\n'.format(resultados))\n",
    "\n",
    "#------------------------Retorna a média dos resultados-----------------------#\n",
    "print('média: {}\\n'.format(resultados.mean()))\n",
    "\n",
    "#--------------------Retorna o desvio padrão dos resultados-------------------#\n",
    "# Valores altos de desvio padrão indicam overfitting                          #\n",
    "#-----------------------------------------------------------------------------#\n",
    "print('desvio padrão: {}\\n'.format(resultados.std()))\n",
    "```\n",
    "\n",
    "### **StratifileKFold**\n",
    "\n",
    "É um outro método de fazer validação cruzada, porém um pouco mais eficiente, pois ele garante uma boa distribuição entre os dados para teste e treinamento. Para efetuar esse processo siga o código:\n",
    "\n",
    "```python\n",
    "#------------------------Pegando os valores pre processados-------------------#\n",
    "# Não divida em base de treinamento e teste.                                  #\n",
    "# Pegar apenas previsores e classe como um todo                               #\n",
    "#-----------------------------------------------------------------------------#\n",
    "\n",
    "#---------------------------------Bibliotecas---------------------------------#\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "# import classe necessária para o método desejado\n",
    "\n",
    "#-------------Criação do objeto que fará a divisão dos dados------------------#\n",
    "# n_splits: número de divisões.                                               #\n",
    "# shuffle: garantir aleatoriedade da divisão dos dados.                       #\n",
    "#-----------------------------------------------------------------------------#\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "#--------------Criação de listas necessárias para os métodos------------------#\n",
    "b = np.zeros(shape = (previsores.shape[0],1))\n",
    "resultados = []\n",
    "\n",
    "#---Divide os indices dos dados de treinamento e teste para cada treinamento--#\n",
    "for indice_treinamento, indice_teste in kfold.split(previsores, b):\n",
    "    #----------------Criar classificador com o método desejado----------------#\n",
    "                                        #\n",
    "                                        #\n",
    "    #--------------------------Utilizando o método fit------------------------#\n",
    "    classificador.fit(previsores[indice_treinamento], classe[indice_treinamento])\n",
    "\n",
    "    #----Passando os dados de teste palas árvores e armazenando as previsões--#\n",
    "\n",
    "    previsoes = classificador.predict(previsores[indice_teste])\n",
    "\n",
    "    #------------Verificando a precisão e acumando em uma lista---------------#\n",
    "    precisao = accuracy_score(classe[indice_teste], previsoes)\n",
    "    resultados.append(precisao)\n",
    "\n",
    "#----------Passando para arry para retirar a média e desvio padrão----------#\n",
    "resultados = np.asanyarray(resultados)\n",
    "print('precisão: {} \\n' .format(resultados.mean()))\n",
    "print('desvio padrão: {} \\n' .format(resultados.std()))\n",
    "\n",
    "```\n",
    "Para exemplificar será utilizado novamente o método de Naive Bayes\n",
    "\n",
    "- **Classe**:\n",
    "    - [sklearn.model_selection.StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html)\n",
    "\n",
    "```python\n",
    "#---------------------------------Bibliotecas---------------------------------#\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#-------------Criação do objeto que fará a divisão dos dados------------------#\n",
    "# n_splits: número de divisões.                                               #\n",
    "# shuffle: garantir aleatoriedade da divisão dos dados.                       #\n",
    "#-----------------------------------------------------------------------------#\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "#--------------Criação de listas necessárias para os métodos------------------#\n",
    "b = np.zeros(shape = (previsores.shape[0],1))\n",
    "resultados = []\n",
    "\n",
    "#---Divide os índices dos dados de treinamento e teste para cada treinamento--#\n",
    "for indice_treinamento, indice_teste in kfold.split(previsores, b):\n",
    "    #----------------Criar classificador com o método desejado----------------#\n",
    "    classificador = GaussianNB()\n",
    "\n",
    "    #--------------------------Utilizando o método fit------------------------#\n",
    "    classificador.fit(previsores[indice_treinamento], classe[indice_treinamento])\n",
    "\n",
    "    #----Passando os dados de teste palas árvores e armazenando as previsões--#\n",
    "\n",
    "    previsoes = classificador.predict(previsores[indice_teste])\n",
    "\n",
    "    #-----------Verificando a precisão e acumulando em uma lista--------------#\n",
    "    precisao = accuracy_score(classe[indice_teste], previsoes)\n",
    "    resultados.append(precisao)\n",
    "\n",
    "#----------Passando para arry para retirar a média e desvio padrão----------#\n",
    "resultados = np.asanyarray(resultados)\n",
    "print('precisão: {} \\n' .format(resultados.mean()))\n",
    "print('desvio padrão: {} \\n' .format(resultados.std()))\n",
    "```\n",
    "\n",
    "## VERIFICANDO O MELHOR CÓDIGO\n",
    "\n",
    "Para isso vamos utilizar o teste de Friedman e Nemenyi.\n",
    "- Friedman: Se existe diferença entre os dados.\n",
    "- Nemenyi: Se existe diferença estatística entre os dados.\n",
    "\n",
    "Caso o teste de Friedman acuse que existe diferença partimos para o teste de Nemenyi.\n",
    "\n",
    "- 1. Efetue a validação cruzada para cada um dos métodos.\n",
    "    - 30 vezes cada método com o random_state mudando de 1 a cada validação.\n",
    "\n",
    "- 2. Monte uma tabela com os resultados das precisões para cada valor de random_state e retira a media.\n",
    "    \n",
    "|random_state|Naive Bayes|Árvore|Random Forest|\n",
    "|-|-|-|-|\n",
    "|1|precisão 1|precisão 1|precisão 1|\n",
    "|2|precisão 2|precisão 2|precisão 2|\n",
    "|.|.|.|.|\n",
    "|.|.|.|.|\n",
    "|.|.|.|.|\n",
    "|30|precisão 30|precisão 30|precisão 30|\n",
    "|Média|Média Naive Bayes|Média Árvore|Média Random Forest|\n",
    "    \n",
    "- 3. Para cada valor de random_state veja em que posição (1º, 2º,...) ficou cada um dos algoritmos\n",
    "    - Exemplo: precisão 1(Naive Bayes) > precisão 1(Random Forest) > precisão 1(Árvore)\n",
    "               precisão 2(Random Forest) > precisão 2(Naive Bayes) > precisão 2(Árvore)\n",
    "               precisão 30(Naive Bayes) > precisão 30(Árvore) > precisão 30(Random Forest)\n",
    "               Média Naive Bayes > Média Árvore > Média Random Forest\n",
    "    - Utilize uma função [ORDEM.MÉD](https://help.libreoffice.org/Calc/Statistical_Functions_Part_Five/pt-BR#ORDEM.M.C3.89D) que exite no libreoffice, ou crie a sua no python.\n",
    "    \n",
    "|random_state|Naive Bayes|Árvore|Random Forest|\n",
    "|-|-|-|-|\n",
    "|1|1|3|2|\n",
    "|2|2|3|1|\n",
    "|.|.|.|.|\n",
    "|.|.|.|.|\n",
    "|.|.|.|.|\n",
    "|30|1|2|3|\n",
    "|Média|1|2|3|\n",
    "    \n",
    "- 4. Salve essa ultima tabela em formato .csv.\n",
    "- 5. Baixe e instale o [R](http://nbcgib.uesc.br/mirrors/cran/) e a biblioteca [TStools](http://kourentzes.com/forecasting/2014/04/19/tstools-for-r/).\n",
    "- 6. Execute o código abaixo no R:\n",
    "\n",
    "```R\n",
    "#---------------------------------Biblioteca----------------------------------#\n",
    "require(TStools)\n",
    "\n",
    "#-----------------------------Passando os dados-------------------------------#\n",
    "dados <- read.csv(\"dados-testes.csv\")\n",
    "\n",
    "#------------------Transformando os dados na forma de matriz------------------#\n",
    "matriz <- as.matrix(dados)\n",
    "\n",
    "#--------------Efetuando o teste de friedman e nemenyi na matriz--------------#\n",
    "TStools::nemenyi(matriz, conf.int = 0.95, plottype = \"vline\")\n",
    "\n",
    "```\n",
    "Para esse teste foi utilizada a base de dados credit_data.csv, o resultado que foi obtido foi a figura abaixo:\n",
    "\n",
    "![](https://github.com/LucasFDutra/Estudos-De-Machine-Learning/blob/master/021%20-%20Valida%C3%A7%C3%A3o/Imagens/Figura.png?raw=true)\n",
    "\n",
    "Veja que na figura temos o indicativo de que há diferença no teste de Friedman. Sendo assim vamos olhar o gráfico que é o teste de Nemenyi.\n",
    "\n",
    "Se Quisermos saber se um algoritmo é superior ao outro o valor que temos entre eles deve ser maior que o valor dado por CD.\n",
    "                                                                                                                   \n",
    "- Exemplo: RNA = 1, Random Forest = 2.33, CD = 1.917\n",
    "    \n",
    "    2.33 - 1 = 1.33 < 1.917. Logo RNA não é superior a Random Forest nessa base de dados.\n",
    "\n",
    "Para facilitar a interpretação do gráfico, veja que temos linhas traçadas na vertical e pontilhadas na horizontal. se uma linha vertical ligar dois pontos sem cortar nenhum pontilhado horizontal quer dizer que não é superior, caso corte algum é superior.\n",
    "\n",
    "> OBS.: O método que possui o menor valor é considerado o melhor método (caso passe nos testes)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
