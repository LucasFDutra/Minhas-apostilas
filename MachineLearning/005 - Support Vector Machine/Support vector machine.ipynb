{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8628f22460735694a192765c54ad1eb10f5ca2cc"
   },
   "source": [
    "# Sumário\n",
    "- [1. MÁQUINAS DE VETOR DE SUPORTE - SVM](#1.-MÁQUINAS-DE-VETOR-DE-SUPORTE---SVM)\n",
    "\n",
    "- [2. IMPLEMENTAÇÃO](#2.-IMPLEMENTAÇÃO)\n",
    "  - [2.1 CLASSIFICAÇÃO](#2.1-CLASSIFICAÇÃO)\n",
    "    - [2.1.1 Base de dados](#2.1.1-Base-de-dados)\n",
    "  - [2.2 REGRESSÃO](#2.2-REGRESSÃO)\n",
    "    - [2.2.1 Base de dados](#2.2.1-Base-de-dados)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e89afdf6cff54041d2381981e3b5afa6da8b2430"
   },
   "source": [
    "# **1. MÁQUINA DE VETOR DE SUPORTE - SVM**\n",
    "\n",
    "Esse algoritmo tem por objetivo traçar hiperplanos para dividir os registros. Ou seja, esse algoritmo é muito bom para classificar as coisas.\n",
    "\n",
    "Por se tratar de um algoritmo que executa muitos cálculos é necessário fazer o escalonamento dos dados, caso contrário eles demorarão para serem executados.\n",
    "\n",
    "O SVM também possibilita trabalhar com problemas linearmente e não linearmente separáveis. E também é possível trabalhar com múltiplas classes.\n",
    "\n",
    "![](https://jeremykun.files.wordpress.com/2017/06/svm_solve_by_hand-e1496076457793.gif?w=372)\n",
    "\n",
    "Fonte: https://jeremykun.com/2017/06/05/formulating-the-support-vector-machine-optimization-problem/\n",
    "\n",
    "---\n",
    "- Links para aprender mais:\n",
    "    - [Support Vector Machine - Cognitive Class](https://youtu.be/SekHI55Ukwk)\n",
    "    - [Support Vector Machines: A Visual Explanation with Sample Python Code - Alice Zhao](https://www.youtube.com/watch?v=N1vOgolbjSc)\n",
    "    - [Support Vector Machines - The Math of Intelligence - Siraj Raval](https://www.youtube.com/watch?v=g8D5YL6cOSE)\n",
    "    - [Support Vector Machine - Georgia Tech - Machine Learning - Udacity](https://www.youtube.com/watch?v=eUfvyUEGMD8)\n",
    "    - [Formulating the Support Vector Machine Optimization Problem - j2kun](https://jeremykun.com/2017/06/05/formulating-the-support-vector-machine-optimization-problem/)\n",
    "---    \n",
    "\n",
    "> Com SVM pode-se fazer tanto classificação quanto regressão.\n",
    "\n",
    "- **Parâmetros Importantes**:\n",
    "    - Custo (C): É a penalidade que o código vai receber se efetuar a divisão erroneamente, ou seja, se o custo for alto ele vai evitar ao máximo errar, buscando 100% de acerto. Já se o custo for de 90% ele vai poder errar um pouco menos. Porém essa porcentagem não é exatamente igual a porcentagem de acertos que o modelo terá. É importante ressaltar que se o custo for o maior possível o algoritmo irá trabalha para que a divisão ocorra perfeitamente, porém nem sempre isso é possível e o gasto computacional para isso pode ser muito grande.\n",
    "        - Valores limites de C: $10^{-3} < C < 10^3$\n",
    "    - Kernel: Como existem registros que formam uma distribuição não linear, é necessário aplicar técnicas nos registros para tornar a distribuição linear. Um exemplo é se os registros estivem distribuídos de forma que não é possível traçar um hiperplano para dividir as classes, assim coloca-se os dados em três dimensões, passando a ser possível dividi-los. Existem diversas técnicas, a sklearn nos oferece as seguintes técnicas:\n",
    "        - rbf (gaussiana): default\n",
    "        - linear \n",
    "        - poly\n",
    "        - sigmoid "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e285aa723efd1f40c2996ec02276a1ef80d4c010"
   },
   "source": [
    "# **2. IMPLEMENTAÇÃO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "16abee1e881f56bff8b39a929a6a25cab8a3cda1"
   },
   "source": [
    "## 2.1 CLASSIFICAÇÃO\n",
    "Para a implementação do algoritmo foi utilizada a biblioteca Sklearn, veja a [Documentação](https://scikit-learn.org/stable/modules/classes.html#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9a7b984423eb7470cad8876e2f3f8c753ef7d680"
   },
   "source": [
    "### **2.1.1 Base de dados**\n",
    "A base de dados que será utilizada será a MNIST que já pode ser encontrada na base de dados do keras.\n",
    "Porém para trabalhar com o algoritmo em questão ela deve modificada em sua dimensão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "c2a3a8d78b9de472359c812a6304365ebf6cdc95"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "# Importando base de dados\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalizando os valores\n",
    "x_train, x_test = x_train/255, x_test/255\n",
    "\n",
    "# Ajustando formato\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2])\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1]*x_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "ec205a718512a42780d9432914333bf7a8dd39db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precisao com linear: 0.9404 \n",
      " matriz de confusão com linear: \n",
      "[[ 957    0    4    1    1    6    9    1    0    1]\n",
      " [   0 1122    3    2    0    1    2    1    4    0]\n",
      " [   8    6  967   11    3    3    7    8   17    2]\n",
      " [   4    3   16  947    1   16    0    9   12    2]\n",
      " [   1    1   10    1  942    2    4    2    3   16]\n",
      " [  10    4    3   36    6  803   13    1   14    2]\n",
      " [   9    2   13    1    5   16  910    1    1    0]\n",
      " [   1    8   21   10    8    1    0  957    3   19]\n",
      " [   8    4    6   25    7   26    6    7  877    8]\n",
      " [   7    7    2   11   33    4    0   18    5  922]]\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------Bibliotecas-----------------------------------#\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "#------------------------Criando classificador linear-------------------------#\n",
    "classificador_linear = SVC(kernel = 'linear', random_state = 0)\n",
    "classificador_linear.fit(x_train, y_train)\n",
    "\n",
    "#-------------------------Previsões kernel linear-----------------------------#\n",
    "previsoes = classificador_linear.predict(x_test)\n",
    "\n",
    "#----------Exibindo a precisão e a matriz de confusão kernel linear-----------#\n",
    "precisao = accuracy_score(y_test, previsoes)\n",
    "matriz = confusion_matrix(y_test, previsoes)\n",
    "print('precisao com linear: {}'.format(precisao),'\\n','matriz de confusão com linear: \\n{}' .format(matriz))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6db3498b83de90fd50ad5783681c8d5ab2f23efa"
   },
   "source": [
    "## 2.2 REGRESSÃO\n",
    "\n",
    "- Observações importantes:\n",
    "    - Utilizando kernel = linear: Temos uma regressão [linear](https://www.kaggle.com/lucasfdutra/regress-o-linear).\n",
    "    - Utilizando kernel = poly: Temos uma regressão [polinomial](https://www.kaggle.com/lucasfdutra/regress-o-polinomial).\n",
    "\n",
    "Para a implementação do algoritmo foi utilizada a biblioteca Sklearn, veja a [Documentação](https://scikit-learn.org/stable/modules/classes.html#)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "384a4b4335fd00af335e8e778c7dbfdd063fd94d"
   },
   "source": [
    "### **2.2.1 Base de dados**\n",
    "A base de dados que será utilizada será a Boston housing price que já pode ser encontrada na base de dados do keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "0a8feaec6aa95be1c193dce0376f36d85f5a5197"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing\n",
    "(x, y),(_,_) = boston_housing.load_data(test_split=0)\n",
    "y = y.reshape(y.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "3da402d4f6335ebedcde3dd88a52e2bcad3de8cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A correlação do modelo rbf com a base de dados de treinamento é de: 0.8684960148369134\n",
      "A correlação do modelo rbf com a base de dados de teste é de: 0.8541612182077774\n",
      "Erro absoluto: 0.2354342260789991\n",
      "Erro quadratico: 0.12378405587665699\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------Bibliotecas-----------------------------------#\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "#------------------------------Escalonando------------------------------------#\n",
    "# Exclusivamente para o rbf é necessário efetuar o escalonamento dos valores. #\n",
    "#-----------------------------------------------------------------------------#\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_x = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "x = scaler_x.fit_transform(x)\n",
    "y = scaler_y.fit_transform(y)\n",
    "\n",
    "#----------------------dividindo a base de treinamento------------------------#\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.3, random_state = 0) # 30% de test\n",
    "y_train = y_train.reshape(y_train.shape[0],)\n",
    "y_test = y_test.reshape(y_test.shape[0],)\n",
    "\n",
    "#---------------------------Criando regressor rbf-----------------------------#\n",
    "regressor = SVR(kernel = 'rbf', gamma = 'auto')\n",
    "regressor.fit(x_train, y_train)\n",
    "\n",
    "#----Ver a correlação do modelo com relação a base de dados de Treinamento----#\n",
    "score = regressor.score(x_train, y_train)\n",
    "print('A correlação do modelo rbf com a base de dados de treinamento é de: {}'.format(score))\n",
    "\n",
    "#-----Ver a correlação do modelo rbf com relação a base de dados de teste-----#\n",
    "score = regressor.score(x_test, y_test)\n",
    "print('A correlação do modelo rbf com a base de dados de teste é de: {}'.format(score))\n",
    "\n",
    "#-----------------------------Previsões kernel--------------------------------#\n",
    "# inverse_transform: para colocar o resultado na escala original              #\n",
    "# colocar o scaler_y pois o valor da previção sai no eixo y                   #\n",
    "#-----------------------------------------------------------------------------#\n",
    "previsoes = regressor.predict(x_test)\n",
    "\n",
    "#-----------------Diferança entre valores reais e previstos-------------------#\n",
    "erro_absoluto = mean_absolute_error(y_test, previsoes)\n",
    "erro_quadratico = mean_squared_error(y_test, previsoes)\n",
    "print('Erro absoluto: {}'.format(erro_absoluto))\n",
    "print('Erro quadratico: {}'.format(erro_quadratico))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
