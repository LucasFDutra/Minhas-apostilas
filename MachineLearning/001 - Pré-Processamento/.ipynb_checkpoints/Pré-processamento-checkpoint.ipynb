{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "98358fce080447786b5f20f0933c4450f683aad7"
   },
   "source": [
    "# Sumário\n",
    "\n",
    "- **[1.  PRÉ-PROCESSAMENTO COM PANDAS E SCIKIT-LEARN](#1.-PRÉ-PROCESSAMENTO-COM-PANDAS-E-SCIKIT-LEARN)**\n",
    "    - [1.1 TIPOS DE VARIÁVEIS](#1.1-TIPOS-DE-VARIÁVEIS)\n",
    "    - [1.2  ENVIANDO BASE DE DADOS PARA O PANDAS](#1.2-ENVIANDO-BASE-DE-DADOS-PARA-O-PANDAS)\n",
    "    - [1.3 TRATAMENTO DE VALORES](#1.3-TRATAMENTO-DE-VALORES)\n",
    "    - [1.4 TRATAMENTO DE VALORES FALTANTES](#1.4-TRATAMENTO-DE-VALORES-FALTANTES)\n",
    "        - [1.4.1 Tratamento de valores faltantes com sklearn](#1.4.1-Tratamento-de-valores-faltantes-com-sklearn)\n",
    "    - [1.5 ESCALONAMENTO DE ATRIBUTOS](#1.5-ESCALONAMENTO-DE-ATRIBUTOS)\n",
    "        - [1.5.1 Escalonamento de atributos com sklearn](#1.5.1-Escalonamento-de-atributos-com-sklearn)\n",
    "    - [1.6 TRANSFORMAÇÃO DE VARIÁVEIS CATEGÓRICAS](#1.6-TRANSFORMAÇÃO-DE-VARIÁVEIS-CATEGÓRICAS)\n",
    "        - [1.6.1 Transformação de variáveis categóricas com sklearn](#1.6.1-Transformação-de-variáveis-categóricas-com-sklearn)\n",
    "        - [1.6.2 Criação de variáveis do tipo dummy](#1.6.2-Criação-de-variáveis-do-tipo-dummy)\n",
    "            - [1.6.2.1 Criação de variáveis do tipo dummy com sklearn](#1.6.2.1-Criação-de-variáveis-do-tipo-dummy-com-sklearn)\n",
    "    - [1.7 DIVISÃO DA BASE DE DADOS EM TREINAMENTO E TESTE](#1.7-DIVISÃO-DA-BASE-DE-DADOS-EM-TREINAMENTO-E-TESTE)\n",
    "        - [1.7.1 Divisão da base de dados em treinamento e teste com sklearn](#1.7.1-Divisão-da-base-de-dados-em-treinamento-e-teste-com-sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "98358fce080447786b5f20f0933c4450f683aad7"
   },
   "source": [
    "# **1. PRÉ-PROCESSAMENTO COM PANDAS E SCIKIT-LEARN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "98358fce080447786b5f20f0933c4450f683aad7"
   },
   "source": [
    "## 1.1 TIPOS DE VARIÁVEIS\n",
    "\n",
    "As variáveis podem se dividir em numéricas e categóricas.\n",
    "\n",
    "- **Numéricas**: São variáveis na forma de números.\n",
    "    - Contínua: Números reais (float).\n",
    "    - Discreta: Números inteiros. \n",
    "    \n",
    "          \n",
    "- **Categóricas**: são basicamente strings.\n",
    "    - Nominal: Não possui ordenação, ou seja, as variáveis não seguem uma sequência.\n",
    "        - **Exemplo**: Cor dos olhos → azul não vem antes de castanho.\n",
    "        \n",
    "    - Ordinal: Essas sim possuem uma ordem.\n",
    "        - **Exemplo**: Tamanho de camisa → P, M, G\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "98358fce080447786b5f20f0933c4450f683aad7"
   },
   "source": [
    "## 1.2 ENVIANDO BASE DE DADOS PARA O PANDAS\n",
    "\n",
    "- 1. Baixe e copie o arquivo da sua base de dados em uma determinada pasta.\n",
    "- 2. Nessa mesma pasta crie o arquivo python com o código.\n",
    "\n",
    "- **Biblioteca**:\n",
    "    - [Pandas](http://pandas.pydata.org/pandas-docs/stable/)\n",
    "- **Base de Dados**:\n",
    "    - credit_data.csv\n",
    "\n",
    "> OBS.: Se tiver duvidas de como inserir uma base de dados no kaggle, nesse kernel [aqui](https://www.kaggle.com/lucasfdutra/regras-de-associa-o?scriptVersionId=10604491) (mais ou menos na metade dele) eu mostrei como fazer isso.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "72f120f9812774be590fbb4984ddef3c90136bf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base de dados:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clientid</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>loan</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>66155.925095</td>\n",
       "      <td>59.017015</td>\n",
       "      <td>8106.532131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>34415.153966</td>\n",
       "      <td>48.117153</td>\n",
       "      <td>6564.745018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>57317.170063</td>\n",
       "      <td>63.108049</td>\n",
       "      <td>8020.953296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>42709.534201</td>\n",
       "      <td>45.751972</td>\n",
       "      <td>6103.642260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>66952.688845</td>\n",
       "      <td>18.584336</td>\n",
       "      <td>8770.099235</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clientid        income        age         loan  default\n",
       "0         1  66155.925095  59.017015  8106.532131        0\n",
       "1         2  34415.153966  48.117153  6564.745018        0\n",
       "2         3  57317.170063  63.108049  8020.953296        0\n",
       "3         4  42709.534201  45.751972  6103.642260        0\n",
       "4         5  66952.688845  18.584336  8770.099235        1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#---------------------------------Bibliotecas---------------------------------#\n",
    "import pandas as pd\n",
    "\n",
    "#----------------Coloca a base de dados na variável 'base'--------------------#\n",
    "base = pd.read_csv('../input/credit-data/credit_data.csv')   # pd.read_csv -> ler arquivos .cvs\n",
    "print('Base de dados:')\n",
    "base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "360b41c397db563a2bcf0bb63b335609b596be12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Informações: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clientid</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>loan</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1000.500000</td>\n",
       "      <td>45331.600018</td>\n",
       "      <td>40.807559</td>\n",
       "      <td>4444.369695</td>\n",
       "      <td>0.141500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>577.494589</td>\n",
       "      <td>14326.327119</td>\n",
       "      <td>13.624469</td>\n",
       "      <td>3045.410024</td>\n",
       "      <td>0.348624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20014.489470</td>\n",
       "      <td>-52.423280</td>\n",
       "      <td>1.377630</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>500.750000</td>\n",
       "      <td>32796.459717</td>\n",
       "      <td>28.990415</td>\n",
       "      <td>1939.708847</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          clientid        income     ...              loan      default\n",
       "count  2000.000000   2000.000000     ...       2000.000000  2000.000000\n",
       "mean   1000.500000  45331.600018     ...       4444.369695     0.141500\n",
       "std     577.494589  14326.327119     ...       3045.410024     0.348624\n",
       "min       1.000000  20014.489470     ...          1.377630     0.000000\n",
       "25%     500.750000  32796.459717     ...       1939.708847     0.000000\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#----------------Puxando algumas informações da base de dados-----------------#\n",
    "print('\\n Informações: ')\n",
    "base.describe().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "40eec7bf8614da7a2f1c4f06e8d1b7c0bd639a2b"
   },
   "source": [
    "Analisando os atributos da base de dados:\n",
    "\n",
    "- Clientid: Temos o número de cada cliente, veja que apesar de o valor ser um número inteiro a variável é tida como categórica e nominal, isso porque o cliente 1 não difere do cliente 2, ele só veio antes porque esta em formato de lista, mas a ordem não importa.\n",
    "\n",
    "\n",
    "- Income: Temos o salário anual, que por sua vez é uma variável numérica contínua.\n",
    "\n",
    "\n",
    "- Age: Temos a idade de cada cliente, que é dada como variável numérica contínua (a idade é quebrada em meses e dias nesse caso).\n",
    "\n",
    "\n",
    "- Loan: É valor do empréstimo que o cliente deseja, que também é dado em variável numérica contínua.\n",
    "\n",
    "\n",
    "- Default: Temos uma variável numérica discreta, sendo:\n",
    "    - 0 → não pagou o empréstimo\n",
    "    - 1 → pagou o empréstimo\n",
    "\n",
    "O comando `base.describe()` é para obtermos informações sobre nossa base de dados.\n",
    "\n",
    "- count: Número de linhas\n",
    "- mean: Média\n",
    "- std: Desvio padrão\n",
    "- min: Valor mínimo\n",
    "- 25%: Percentil 25% \n",
    "- 50%: Percentil 50% (mediana) \n",
    "- 75%: Percentil 75% \n",
    "- max: Valor máximo \n",
    "\n",
    "> OBS.: O valor descrito no percentil significa que quando chegamos a `x%` da base de dados o valor que ali esta é `y`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "40eec7bf8614da7a2f1c4f06e8d1b7c0bd639a2b"
   },
   "source": [
    "## 1.3 TRATAMENTO DE VALORES\n",
    "\n",
    "No processo de captura de dados temos sempre que tomar cuidado com registros que possuem inconsistência, pois eles atrapalham toda a analise. Um exemplo disso pode ser observado na tabela de informações que o pandas gerou, em que o dado de idade mínima (linha 4 coluna 3) temos um valor de idade negativo, o que é impossível. Sendo assim temos que tratar esses dados para depois utilizá-los.\n",
    "\n",
    "Para tal temos algumas opções:\n",
    "\n",
    "- 1. Apagar todo o atributo com problemas.\n",
    "      - Não é muito viável, pois perde-se um atributo inteiro de informação que pode ser importante para a analise.\n",
    "      \n",
    "      \n",
    "- 2. Apagar o registro com problemas.\n",
    "      - Costuma não ser muito aconselhável, porém se tivermos uma base de dados grandes o suficiente e poucos registros problemáticos, pode ser que eles não façam falta.\n",
    "      \n",
    "      \n",
    "- 3. Procurar o dono do registro e corrigi-lo.\n",
    "      - É a melhor, porém em muitos casos inviável de ser executada.\n",
    "      \n",
    "      \n",
    "- 4. Substituir os atributos do registro que possui erros pela média dos valores das variáveis independentes daquele atributo (somente daqueles valores que são válidos).\n",
    "      - É dentre todas a melhor, e no caso do exemplo anterior, essa sera a opção adotada.\n",
    "\n",
    "Para substituir as variáveis erradas pela média, faz-se:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "c29382baeac21dc687def5356d1d4230972588ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Idades negativas: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clientid</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>loan</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>50501.726689</td>\n",
       "      <td>-28.218361</td>\n",
       "      <td>3977.287432</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>32197.620701</td>\n",
       "      <td>-52.423280</td>\n",
       "      <td>4244.057136</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>63287.038908</td>\n",
       "      <td>-36.496976</td>\n",
       "      <td>9595.286289</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    clientid        income        age         loan  default\n",
       "15        16  50501.726689 -28.218361  3977.287432        0\n",
       "21        22  32197.620701 -52.423280  4244.057136        0\n",
       "26        27  63287.038908 -36.496976  9595.286289        0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#------------------mostra quem esta menor que zero em age---------------------#\n",
    "print('# Idades negativas: ')\n",
    "base.loc[base['age'] < 0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "1d78c9c0a6eca3b7b794d6945874e976bb0929bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Veja que ninguém possui idade negativas agora: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clientid</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>loan</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [clientid, income, age, loan, default]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#---------------------------Substitui pela média------------------------------#\n",
    "media = base['age'][base.age > 0].mean()\n",
    "base.loc[base.age < 0, 'age'] = media\n",
    "\n",
    "#--------------------Repetindo o comando de verificação-----------------------#\n",
    "print('\\n# Veja que ninguém possui idade negativas agora: ')\n",
    "base.loc[base['age'] < 0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "842d201ae854135b6e16bc5a7ad73ccc805ba3b8"
   },
   "source": [
    "Caso decida adotar as outras alternativas siga uma das duas partes do código abaixo:\n",
    "\n",
    "```python\n",
    "#------------------------------Apaga a coluna---------------------------------#\n",
    "base.drop('age',1,inplace=True)\n",
    "    \n",
    "#-------------------------------Apaga a Linha---------------------------------#\n",
    "base.drop(base[base.age < 0].index, inplace = True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "842d201ae854135b6e16bc5a7ad73ccc805ba3b8"
   },
   "source": [
    "## 1.4 TRATAMENTO DE VALORES FALTANTES\n",
    "\n",
    "No exemplo anterior, note que a quantidade de variáveis existentes na coluna ‘age’ é de 1997, o que significa que temos 3 valores faltando.\n",
    "\n",
    "Para resolver esse problema temos três estratégias, são elas:\n",
    "\n",
    "- 1. Substituir os valores faltantes pela média.\n",
    "      - Bom para casos em que os atributos em questão são idade, salário, peso, etc.\n",
    "      \n",
    "      \n",
    "- 2. Substituir os valores faltantes pela mediana.\n",
    "      - Quando as distribuições numéricas estão distorcidas, é conveniente utilizar a mediana, pois ela pega a tendência central dos dados.\n",
    "      \n",
    "      \n",
    "- 3. Substituir os valores faltantes pela moda (mais frequente).\n",
    "      - Bom para casos em que os dados são cor dos olhos, nacionalidade, etc.\n",
    "      \n",
    "      \n",
    "> OBS.: Existem algoritmos que conseguem tratar essas viáveis, logo nem sempre é necessário efetuar o pré-processamento. Normalmente quando elas vem como NaN temos que tratá-las."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "842d201ae854135b6e16bc5a7ad73ccc805ba3b8"
   },
   "source": [
    "### **1.4.1 Tratamento de valores faltantes com sklearn**\n",
    "\n",
    "- **Bibliotecas**: \n",
    "    - [scikit-learn](https://scikit-learn.org/stable/modules/classes.html)\n",
    "    - [numpy](http://www.numpy.org/)\n",
    "- **Base de Dados**:\n",
    "    - credit_data.csv\n",
    "    \n",
    "Nesse exemplo vamos seguir pela primeira opção, sendo assim o código será:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "9af695df03709e023d43d0e78d6df6683bc4c07b"
   },
   "outputs": [],
   "source": [
    "#---------------------------------Bibliotecas---------------------------------#\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#---------Alocando os valores das colunas 1 à 3 (dados de analise)------------#\n",
    "previsores = base.iloc[:, 1:4].values\n",
    "\n",
    "#----------------Alocando os valores da coluna 4 (Respostas)------------------#\n",
    "classe = base.iloc[:, 4].values\n",
    "\n",
    "#-----------------------Criando um objeto Imputer-----------------------------#\n",
    "#  Pegar os valores com NaN e como estrategia ele os substituirá pela media   #\n",
    "#-----------------------------------------------------------------------------#\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy='mean')\n",
    "\n",
    "#-------Encontra os parâmetros para preprocessar (fit) e os transforma--------#\n",
    "previsores[:,0:3] = imputer.fit_transform(previsores[:,0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ad65e5cc8470bff5531b6b116f69a597bec7317e"
   },
   "source": [
    "## 1.5 ESCALONAMENTO DE ATRIBUTOS\n",
    "\n",
    "Temos que tomar cuidado com os algoritmos que utilizamos, pois dependendo do algoritmo, podemos retirar conclusões erradas. No exemplo que estamos seguindo, a idade é um atributo que não varia muito, mas os valores de salário anual sim. Logo um algoritmo que se baseia em distancias euclidianas consideraria os dados de salário mais relevantes do que os de idade. Assim devemos efetuar o escalonamento (colocar tudo na mesma base), o qual pode ser feito de duas formas:\n",
    "\n",
    "- Padronização\n",
    "- Normalização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ad65e5cc8470bff5531b6b116f69a597bec7317e"
   },
   "source": [
    "### **1.5.1 Escalonamento de atributos com sklearn**\n",
    "\n",
    "[Padronização](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler): $x=\\dfrac{x - média(dados)}{DesvioPadrão(dados)}$\n",
    "```python\n",
    "#---------------------------------Bibliotecas---------------------------------#\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#---------Cria um objeto que vai fazer o escalonamento por padronização-------#\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#----------------------Ajusta os valores de previsores------------------------#\n",
    "previsores = scaler.fit_transform(previsores)\n",
    "```\n",
    "\n",
    "[Normalização](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html#sklearn.preprocessing.Normalizer): $x=\\dfrac{x - mínimo(dados)}{máximo(dados) - mínimo(dados)}$\n",
    "```python\n",
    "#---------------------------------Bibliotecas---------------------------------#\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "#---------Cria um objeto que vai fazer o escalonamento por padronização-------#\n",
    "norma = Normalizer()\n",
    "\n",
    "#----------------------Ajusta os valores de previsores------------------------#\n",
    "previsores = norma.fit_transform(previsores)\n",
    "```\n",
    "Nesse exemplo seguiremos com a padronização.\n",
    "- **Base de Dados**:\n",
    "    - credit_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "298201d6273b21f4fa8837d9ff79a7494e3cda76"
   },
   "outputs": [],
   "source": [
    "#---------------------------------Bibliotecas---------------------------------#\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#---------Cria um objeto que vai fazer o escalonamento por padronização-------#\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#----------------------Ajusta os valores de previsores------------------------#\n",
    "previsores = scaler.fit_transform(previsores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a0186fdfe324ec38cee846f6613f31e594c20cea"
   },
   "source": [
    "## 1.6 TRANSFORMAÇÃO DE VARIÁVEIS CATEGÓRICAS \n",
    "\n",
    "Como já visto antes, variáveis categóricas são tidas como strings, porém para que o computador trabalhe, precisamos convertê-las para variáveis numéricas discretas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a0186fdfe324ec38cee846f6613f31e594c20cea"
   },
   "source": [
    "### **1.6.1 Transformação de variáveis categóricas com sklearn**\n",
    "- **Base de Dados**:\n",
    "    - census.cvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "74a692fa3bf50f7ecca179ea03d597995014af33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Previsores antes da conversão: \n",
      "[[39 ' State-gov' 77516 ... 0 40 ' United-States']\n",
      " [50 ' Self-emp-not-inc' 83311 ... 0 13 ' United-States']\n",
      " [38 ' Private' 215646 ... 0 40 ' United-States']\n",
      " ...\n",
      " [58 ' Private' 151910 ... 0 40 ' United-States']\n",
      " [22 ' Private' 201490 ... 0 20 ' United-States']\n",
      " [52 ' Self-emp-inc' 287927 ... 0 40 ' United-States']]\n",
      "\n",
      "# Previsores após a conversão: \n",
      "[[39 7 77516 ... 0 40 39]\n",
      " [50 6 83311 ... 0 13 39]\n",
      " [38 4 215646 ... 0 40 39]\n",
      " ...\n",
      " [58 4 151910 ... 0 40 39]\n",
      " [22 4 201490 ... 0 20 39]\n",
      " [52 5 287927 ... 0 40 39]]\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------Bibliotecas-----------------------------------#\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#----------------Coloca a base de dados na variável 'base'--------------------#\n",
    "base = pd.read_csv('../input/census/census.csv')\n",
    "\n",
    "#----------Alocando os valores das colunas em previsores e classes------------#\n",
    "previsores = base.iloc[:,0:14].values\n",
    "classe = base.iloc[:,14].values\n",
    "print('# Previsores antes da conversão: ')\n",
    "print(previsores)\n",
    "\n",
    "#------Definindo um objeto LabelEncoder que é responsável pela conversão------#\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "#-------Verificando onde estão as variáveis categóricas e as convertendo------#\n",
    "for i in range(len(previsores[0])):\n",
    "    if type(previsores[0][i]) == str:\n",
    "        previsores[:,i] = labelencoder.fit_transform(previsores[:,i])\n",
    "\n",
    "print('\\n# Previsores após a conversão: ')\n",
    "print(previsores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4aa2cd7d01aa44daf398515fcaf0e4b22f6cb86b"
   },
   "source": [
    "Após a conversão temos as variáveis que antes eram strings convertidos para numéricas. Ou seja, a classe [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder) definiu valores numéricos para cada uma das palavras e as substituiu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4aa2cd7d01aa44daf398515fcaf0e4b22f6cb86b"
   },
   "source": [
    "### **1.6.2 Criação de variáveis do tipo dummy**\n",
    "\n",
    "O problema do código anterior é que a conversão feita daquela maneira, nem sempre é viável, porque se tivermos variáveis categóricas nominais e adotarmos valores para elas, vamos acabar estabelecendo uma ordem. Isso é errado, pois agora existe uma ordem entre as variáveis, afinal 1<2<3<...<n. Para evitar esse problema deve-se criar variáveis do tipo dummy.\n",
    "\n",
    "Na criação dessas variáveis temos que particionar as colunas com variáveis nominais, assim se dentro de uma dada coluna tivéssemos três dados diferentes, dividiríamos essa coluna em três, e colocaríamos 1 para quando ela ocorresse, e 0 para quando não ocorresse. \n",
    "\n",
    "- **Exemplo**: Se tivermos a seguinte distribuição:\n",
    "\n",
    "|Pessoas| País |\n",
    "|-|------|\n",
    "|1|Brasil|\n",
    "|2|EUA   |\n",
    "|3|Canada|\n",
    "|4|Brasil|\n",
    "\n",
    "    Do modo convencional, a conversão seria feita da seguinte forma:\n",
    "\n",
    "|Pessoas|País|\n",
    "|-|-|\n",
    "|1|1|\n",
    "|2|2|\n",
    "|3|3|\n",
    "|4|1|\n",
    "\n",
    "    O que passa a ideia de que Canada>Estados Unidos>Brasil.\n",
    " \n",
    "    Agora se utilizarmos a criação de variáveis do tipo dummy, a conversão será da seguinte forma:\n",
    "\n",
    "|Pessoas| Brasil |EUA|Canada|\n",
    "|-|-|-|-|\n",
    "|1|1|0|0|\n",
    "|2|0|1|0|\n",
    "|3|0|0|1|\n",
    "|4|1|0|0|\n",
    "\n",
    "---\n",
    "- Links para aprender mais:\n",
    "    - [Machine Learning Tutorial Python - 6: Dummy Variables & One Hot Encoding - codebasics](https://www.youtube.com/watch?v=9yl6-HEY7_s)\n",
    "    - [Using categorical data in machine learning with python - yonatan hadar](https://blog.myyellowroad.com/using-categorical-data-in-machine-learning-with-python-from-dummy-variables-to-deep-category-66041f734512), \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4aa2cd7d01aa44daf398515fcaf0e4b22f6cb86b"
   },
   "source": [
    "#### 1.6.2.1 Criação de variáveis do tipo dummy com sklearn\n",
    "\n",
    "- **Base de Dados**:\n",
    "    - census.cvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "1a7c8dd99094d8c56272c76a135e433a7ed6f0e9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Previsores com variáveis dummy: \n",
      " [[-0.2444502  -0.17429511 -0.26209736 ...  0.1484529  -0.21665953\n",
      "  -0.03542945]\n",
      " [-0.2444502  -0.17429511 -0.26209736 ... -0.14592048 -0.21665953\n",
      "  -2.22215312]\n",
      " [-0.2444502  -0.17429511 -0.26209736 ... -0.14592048 -0.21665953\n",
      "  -0.03542945]\n",
      " ...\n",
      " [-0.2444502  -0.17429511 -0.26209736 ... -0.14592048 -0.21665953\n",
      "  -0.03542945]\n",
      " [-0.2444502  -0.17429511 -0.26209736 ... -0.14592048 -0.21665953\n",
      "  -1.65522476]\n",
      " [-0.2444502  -0.17429511 -0.26209736 ...  1.88842434 -0.21665953\n",
      "  -0.03542945]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------Bibliotecas-----------------------------------#\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#----------------Coloca a base de dados na variável 'base'--------------------#\n",
    "base = pd.read_csv('../input/census/census.csv')\n",
    "\n",
    "#----------Alocando os valores das colunas em previsores e classes------------#\n",
    "previsores = base.iloc[:,0:14].values\n",
    "classe = base.iloc[:,14].values\n",
    "\n",
    "#------Definindo um objeto LabelEncoder que é responsável pela conversão------#\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "#---Verificando onde estão as variáveis categóricas e convertendo a classe----#\n",
    "lista_categoricos = []\n",
    "for i in range(len(previsores[0])):\n",
    "    if type(previsores[0][i]) == str:\n",
    "        lista_categoricos.append(i)\n",
    "classe = labelencoder.fit_transform(classe)\n",
    "\n",
    "#---------------------Criando as variáveis do tipo dummy----------------------#\n",
    "ct = ColumnTransformer([('oh_enc', OneHotEncoder(sparse=False), lista_categoricos),],remainder='passthrough')\n",
    "previsores = ct.fit_transform(previsores)\n",
    "\n",
    "#---------------------------------Bibliotecas---------------------------------#\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#---------Cria um objeto que vai fazer o escalonamento por padronização-------#\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#----------------------Ajusta os valores de previsores------------------------#\n",
    "previsores = scaler.fit_transform(previsores)\n",
    "\n",
    "print('# Previsores com variáveis dummy: \\n {}'.format(previsores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4f8c946fb6b20acb75fbdb0aa10b954410f18bca"
   },
   "source": [
    "- **Observações**:\n",
    "\n",
    "    - Primeiramente, ignore o aviso de warnings.\n",
    "    \n",
    "    - Nesse novo exemplo, as variáveis dependentes são dadas por <=50 ou >=50, ou seja, são variáveis do tipo categóricas ordinais, logo, o método utilizado para converter essas variáveis é apenas o LabelEncoder.\n",
    "\n",
    "    - Para gerar as variáveis dummy não é necessário converter as variáveis nominais para numéricas.\n",
    "\n",
    "    - Para identificar as variáveis categóricas eu utilizei uma busca por strings, porém esse não é um método muito viável, pois podemos ter no meio das variáveis independentes variáveis nominais e ordinais, e o tratamento para elas é um pouco diferente, as ordinais param na etapa do LabelEncoder, já as nominais vão até a criação das variáveis dummy. Então deve-se primeiro avaliar o tipo de variável que se encontra em cada atributo, para depois tomar a decisão.\n",
    "    \n",
    "    - Deve-se tomar cuidado ao fazer escalonamento de variáveis do tipo dummy, visto que em caso de existir um atributo indicando um país, não faz sentido escalonarmos ele, pois assim a nossa interpretação fica comprometida, pois a avaliação nesse caso é se a pessoa é ou não daquele pais.\n",
    "\n",
    "    - Sobre o comando `ColumnTransformer: 'oh_enc'` é obrigatório e `remainder='passthrough'` faz com que as variáveis que não sefrerão mudanças permaneçam no array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4f8c946fb6b20acb75fbdb0aa10b954410f18bca"
   },
   "source": [
    "## 1.7 DIVISÃO DA BASE DE DADOS EM TREINAMENTO E TESTE\n",
    "\n",
    "Sempre que tivermos uma base de dados, devemos primeiramente tratá-la para eliminar irregularidade, e posteriormente devemos dividi-la em base de treinamento e de testes. Pois assim com uma dada porcentagem dos registros iremos treinar o algoritmo e a outras verificaremos a sua validade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4f8c946fb6b20acb75fbdb0aa10b954410f18bca"
   },
   "source": [
    "### **1.7.1 Divisão da base de dados em treinamento e teste com sklearn**\n",
    "\n",
    "- **Base de Dados**:\n",
    "    - census.cvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "2c97fb612f53a322f6e7a3a001d2bcc34019b8e9"
   },
   "outputs": [],
   "source": [
    "#-------------------------------Bibliotecas-----------------------------------#\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#-------------------Dividindo os Previsores e as Classes----------------------#\n",
    "# Obs.: test_size = <porcentagem da divisão dos dados>                        #\n",
    "#       nesse caso 25% dos dados serão de teste.                              #\n",
    "#-----------------------------------------------------------------------------#\n",
    "previsores_treinamento, previsores_teste, classe_treinamento, classe_teste = train_test_split(previsores, classe, test_size=0.25, random_state=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
