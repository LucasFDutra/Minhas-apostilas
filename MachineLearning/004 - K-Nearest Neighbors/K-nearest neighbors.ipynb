{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d43f242f50179d5972c7ea5e486cbc1d71db22ef"
   },
   "source": [
    "# **KNN**\n",
    "\n",
    "Ele faz a distância com os `k` vizinhos mais próximos, e analisa quantos desses possui uma determinada classificação e encaixa o objeto de estudo nessa classe. \n",
    "- **Exemplo 1**: Se tivermos 5 círculos da cor verde e 3 da cor vermelha, e queremos saber qual a cor de um dado circulo. O algoritmo calculará a distancia entre esse circulo e os demais, estabelecendo um `k=3` ele vai pegar os 3 mais próximos, se 2 deles forem vermelhos ele classifica o circulo como vermelho. Agora se analisarmos `k=5` pode ocorrer de termos 2 vermelhos e 3 verdes, assim o circulo será classificado como verde. Logo pode-se notar que o valor de `k` afeta o resultado final.\n",
    "\n",
    "- **Exemplo 2**: Suponhamos que 3 pessoas na netflix, `A`, `B` e `C`, deram notas para os filmes `X` e `Y`. \n",
    "\n",
    "|.|X|Y|\n",
    "|-|-|-|\n",
    "|A|3|5|\n",
    "|B|3|4|\n",
    "|C|5|2|\n",
    "    \n",
    "Note que a distancia `AB` é muito menor que a distancia `AC`, assim a pessoa `A` receberá recomendações de filmes com base nos filmes que `B` assistiu.\n",
    "\n",
    "> OBS.: Veja que como o KNN tem base em um cálculo de distância, não podemos utilizar atributos categóricos, assim temos que [converter](#2.6-TRANSFORMAÇÃO-DE-VARIÁVEIS-CATEGÓRICAS) os dados para numéricos e também temos que fazer o [escalonamento](#2.5-ESCALONAMENTO-DE-ATRIBUTOS).\n",
    "\n",
    "O método KNN funciona problemas linearmente e não linearmente separáveis. E assim como os outros ele também é capaz de efetuar classificação de múltiplas classes.\n",
    "\n",
    "![](https://importq.files.wordpress.com/2017/11/knn_neigh.gif?w=656)\n",
    "\n",
    "Fonte: https://importq.wordpress.com/2017/11/24/mnist-analysis-using-knn/\n",
    "\n",
    "![](https://zeidigital.files.wordpress.com/2016/08/class_prediction.jpg?w=640)\n",
    "\n",
    "Fonte: https://zeidigital.wordpress.com/2016/08/13/k-nearest-neighbour-classification-algorithm-implementation-in-python/\n",
    "\n",
    "\n",
    "---\n",
    "- Links para aprender mais:\n",
    "    - [Introdução ao Algoritmo KNN - IAexpert](https://iaexpert.com.br/index.php/2017/10/09/introducao-ao-algoritmo-knn/).\n",
    "    - [K-Nearest Neighbors - Cognitive Class](https://youtu.be/VC3TgpFVcXE)\n",
    "    - [MNIST analysis using KNN - ImportQ](https://importq.wordpress.com/2017/11/24/mnist-analysis-using-knn/)\n",
    "    - [K-Nearest Neighbour(KNN) classification algorithm implementation in Python - Zeiselt](https://zeidigital.wordpress.com/2016/08/13/k-nearest-neighbour-classification-algorithm-implementation-in-python/)\n",
    "---\n",
    "\n",
    "> O Algoritmo KNN pode ser utilizado para classificação e para regressão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d61451fdf45f882330fec59730201c302394e3e2"
   },
   "source": [
    "# **IMPLEMENTAÇÃO**\n",
    "Para a implementação do algoritmo foi utilizada a biblioteca Sklearn, veja a [Documentação](https://scikit-learn.org/stable/modules/classes.html#)\n",
    "\n",
    "## BASE DE DADOS\n",
    "A base de dados que será utilizada será a MNIST que já pode ser encontrada na base de dados do keras.\n",
    "Porém para trabalhar com o algoritmo em questão ela deve modificada em sua dimensão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "a53b997a2036b7a32dad83ccb3851b69f55397be"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "# Importando base de dados\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalizando os valores\n",
    "x_train, x_test = x_train/255, x_test/255\n",
    "\n",
    "# Ajustando formato\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2])\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1]*x_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "a5545cfec137cb630398ed46f9b19fa873ba51b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precisao: 0.9688 \n",
      " matriz de confusão: \n",
      "[[ 974    1    1    0    0    1    2    1    0    0]\n",
      " [   0 1133    2    0    0    0    0    0    0    0]\n",
      " [  11    8  991    2    1    0    1   15    3    0]\n",
      " [   0    3    3  976    1   13    1    6    3    4]\n",
      " [   3    7    0    0  944    0    4    2    1   21]\n",
      " [   5    0    0   12    2  862    4    1    2    4]\n",
      " [   5    3    0    0    3    2  945    0    0    0]\n",
      " [   0   22    4    0    3    0    0  988    0   11]\n",
      " [   8    3    5   13    6   12    5    5  913    4]\n",
      " [   5    7    3    9    7    3    1   10    2  962]]\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------Bibliotecas-----------------------------------#\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "#----------------------------Criando classificador----------------------------# \n",
    "# Com 5 visinhos, métrica minkowski e com p=2 (distância Euclidiana)          #\n",
    "# OBS.: Todos esses parâmetros são default, porém coloquei eles aqui para     #\n",
    "#       Manter a didatica.                                                    #\n",
    "#-----------------------------------------------------------------------------#\n",
    "classificador = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\n",
    "classificador.fit(x_train, y_train)\n",
    "\n",
    "#----Passando os dados de teste pelo algoritmo e armazenando as previsões-----#\n",
    "previsoes = classificador.predict(x_test)\n",
    "\n",
    "#----------------Exibindo a precisão e a matriz de confusão-------------------#\n",
    "precisao = accuracy_score(y_test, previsoes)\n",
    "matriz = confusion_matrix(y_test, previsoes)\n",
    "print('precisao: {}'.format(precisao),'\\n','matriz de confusão: \\n{}' .format(matriz))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
